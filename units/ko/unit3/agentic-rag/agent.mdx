# 갤라 에이전트 만들기

이제 Alfred를 위한 모든 필요한 구성 요소를 구축했으니, 우리의 화려한 갤라를 주최하는 것을 도울 수 있는 완전한 에이전트로 모든 것을 통합해보겠습니다.

이 섹션에서는 손님 정보 검색, 웹 검색, 날씨 정보, Hub 통계 도구를 하나의 강력한 에이전트로 결합하겠습니다.

## Alfred 조립하기: 완전한 에이전트

이전 섹션에서 만든 모든 도구를 다시 구현하는 대신, `tools.py`와 `retriever.py` 파일에 저장한 각 모듈에서 가져오겠습니다.

<Tip>
아직 도구들을 구현하지 않았다면, <a href="./tools">tools</a>와 <a href="./invitees">retriever</a> 섹션으로 돌아가서 구현하고 `tools.py`와 `retriever.py` 파일에 추가하세요.
</Tip>

이전 섹션에서 필요한 라이브러리와 도구들을 가져오겠습니다:

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
# 필요한 라이브러리 가져오기
import random
from smolagents import CodeAgent, InferenceClientModel

# 모듈에서 커스텀 도구 가져오기
from tools import DuckDuckGoSearchTool, WeatherInfoTool, HubStatsTool
from retriever import load_guest_dataset
```

이제 이 모든 도구들을 하나의 에이전트로 결합해보겠습니다:

```python
# Hugging Face 모델 초기화
model = InferenceClientModel()

# 웹 검색 도구 초기화
search_tool = DuckDuckGoSearchTool()

# 날씨 도구 초기화
weather_info_tool = WeatherInfoTool()

# Hub 통계 도구 초기화
hub_stats_tool = HubStatsTool()

# 손님 데이터셋 로드 및 손님 정보 도구 초기화
guest_info_tool = load_guest_dataset()

# 모든 도구를 사용하여 Alfred 생성
alfred = CodeAgent(
    tools=[guest_info_tool, weather_info_tool, hub_stats_tool, search_tool], 
    model=model,
    add_base_tools=True,  # 추가 기본 도구 추가
    planning_interval=3   # 3단계마다 계획 수립 활성화
)
```

</hfoption>
<hfoption id="llama-index">

```python
# 필요한 라이브러리 가져오기
from llama_index.core.agent.workflow import AgentWorkflow
from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI

from tools import search_tool, weather_info_tool, hub_stats_tool
from retriever import guest_info_tool
```

이제 이 모든 도구들을 하나의 에이전트로 결합해보겠습니다:

```python
# Hugging Face 모델 초기화
llm = HuggingFaceInferenceAPI(model_name="Qwen/Qwen2.5-Coder-32B-Instruct")

# 모든 도구를 사용하여 Alfred 생성
alfred = AgentWorkflow.from_tools_or_functions(
    [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool],
    llm=llm,
)
```

</hfoption>
<hfoption id="langgraph">

```python
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages
from langchain_core.messages import AnyMessage, HumanMessage, AIMessage
from langgraph.prebuilt import ToolNode
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition
from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace

from tools import DuckDuckGoSearchRun, weather_info_tool, hub_stats_tool
from retriever import guest_info_tool
```

이제 이 모든 도구들을 하나의 에이전트로 결합해보겠습니다:

```python
# 웹 검색 도구 초기화
search_tool = DuckDuckGoSearchRun()

# 도구를 포함한 채팅 인터페이스 생성
llm = HuggingFaceEndpoint(
    repo_id="Qwen/Qwen2.5-Coder-32B-Instruct",
    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,
)

chat = ChatHuggingFace(llm=llm, verbose=True)
tools = [guest_info_tool, search_tool, weather_info_tool, hub_stats_tool]
chat_with_tools = chat.bind_tools(tools)

# AgentState와 Agent 그래프 생성
class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], add_messages]

def assistant(state: AgentState):
    return {
        "messages": [chat_with_tools.invoke(state["messages"])],
    }

## 그래프
builder = StateGraph(AgentState)

# 노드 정의: 실제 작업을 수행
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# 엣지 정의: 제어 흐름이 어떻게 이동하는지 결정
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    # 최신 메시지가 도구를 필요로 하면 도구로 라우팅
    # 그렇지 않으면 직접 응답 제공
    tools_condition,
)
builder.add_edge("tools", "assistant")
alfred = builder.compile()
```
</hfoption>
</hfoptions>

이제 에이전트를 사용할 준비가 되었습니다!

## Alfred 사용하기: 엔드투엔드 예제

이제 Alfred가 필요한 모든 도구를 갖추었으니, 갤라 중에 다양한 작업을 어떻게 도울 수 있는지 살펴보겠습니다.

### 예제 1: 손님 정보 찾기

Alfred가 손님 정보를 어떻게 도울 수 있는지 살펴보겠습니다.

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
query = "Tell me about 'Lady Ada Lovelace'"
response = alfred.run(query)

print("🎩 Alfred의 응답:")
print(response)
```

예상 출력:

```
🎩 Alfred의 응답:
검색한 정보에 따르면, Lady Ada Lovelace는 존경받는 수학자이자 친구입니다. 그녀는 수학과 컴퓨팅 분야의 선구적인 업적으로 유명하며, Charles Babbage의 해석 기관에 대한 작업으로 인해 종종 최초의 컴퓨터 프로그래머로 기려집니다. 그녀의 이메일 주소는 ada.lovelace@example.com입니다.
```

</hfoption>
<hfoption id="llama-index">

```python
query = "Tell me about Lady Ada Lovelace. What's her background?"
response = await alfred.run(query)

print("🎩 Alfred의 응답:")
print(response.response.blocks[0].text)
```

예상 출력:

```
🎩 Alfred의 응답:
Lady Ada Lovelace는 영국의 수학자이자 작가로, Charles Babbage의 해석 기관에 대한 작업으로 가장 잘 알려져 있습니다. 그녀는 이 기계가 순수 계산 이상의 응용 프로그램을 가지고 있다는 것을 최초로 인식한 사람이었습니다.
```

</hfoption>
<hfoption id="langgraph">

```python
response = alfred.invoke({"messages": "Tell me about 'Lady Ada Lovelace'"})

print("🎩 Alfred의 응답:")
print(response['messages'][-1].content)
```

예상 출력:

```
🎩 Alfred의 응답:
Ada Lovelace는 Augusta Ada King, Lovelace 백작부인으로도 알려진 영국의 수학자이자 작가입니다. 1815년 12월 10일에 태어나 1852년 11월 27일에 사망했으며, 제안된 기계식 범용 컴퓨터인 Charles Babbage의 해석 기관에 대한 작업으로 유명합니다. Ada Lovelace는 1843년에 해석 기관을 위한 프로그램을 만들었기 때문에 최초의 컴퓨터 프로그래머 중 한 명으로 기려집니다. 그녀는 당시 소수만이 그랬던 방식으로 기계가 단순한 계산 이상의 용도로 사용될 수 있다는 잠재력을 인식했습니다. 그녀의 컴퓨터 과학 분야에 대한 기여는 미래의 발전을 위한 기반을 마련했습니다. 10월의 어느 날은 Ada Lovelace Day로 지정되어 있으며, Lovelace의 선구적인 작업에서 영감을 받아 과학과 기술 분야에서의 여성들의 기여를 기리는 날입니다.
```

</hfoption>
</hfoptions>

### 예제 2: 불꽃놀이를 위한 날씨 확인

Alfred가 날씨 정보를 어떻게 도울 수 있는지 살펴보겠습니다.

<hfoptions id="agents-frameworks">
<hfoption id="smolagents">

```python
query = "What's the weather like in Paris tonight? Will it be suitable for our fireworks display?"
response = alfred.run(query)

print("🎩 Alfred의 응답:")
print(response)
```

예상 출력 (무작위성으로 인해 달라질 수 있음):
```
🎩 Alfred의 응답:
파리의 오늘 밤 날씨를 확인해보았습니다. 현재 맑고 기온은 25°C입니다. 이러한 조건은 오늘 밤 불꽃놀이에 완벽합니다. 맑은 하늘은 화려한 쇼를 위한 뛰어난 가시성을 제공할 것이며, 쾌적한 기온은 손님들이 불편함 없이 야외 행사를 즐길 수 있도록 보장할 것입니다.
```

</hfoption>
<hfoption id="llama-index">

```python
query = "What's the weather like in Paris tonight? Will it be suitable for our fireworks display?"
response = await alfred.run(query)

print("🎩 Alfred의 응답:")
print(response)
```

예상 출력:

```
🎩 Alfred의 응답:
파리의 오늘 밤 날씨는 비가 오고 기온은 15°C입니다. 비가 오는 것을 고려할 때, 불꽃놀이에는 적합하지 않을 수 있습니다.
```

</hfoption>
</hfoptions> 