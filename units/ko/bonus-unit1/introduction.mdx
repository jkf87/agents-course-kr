# 소개

![보너스 유닛 1 썸네일](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit1/thumbnail.jpg)

함수 호출을 위해 대규모 언어 모델(LLM)을 파인튜닝하는 방법을 배우는 첫 번째 **보너스 유닛**에 오신 것을 환영합니다.

LLM의 관점에서 함수 호출은 빠르게 *필수 지식*이 되어가고 있습니다.

이 아이디어는 유닛 1에서 했던 것처럼 프롬프트 기반 접근 방식에만 의존하는 대신, 함수 호출은 모델이 **학습 단계에서 액션을 취하고 관찰을 해석하도록** 훈련하여 AI를 더욱 견고하게 만듭니다.

> **이 보너스 유닛은 언제 해야 할까요?**
>
> 이 섹션은 **선택사항**이며 유닛 1보다 더 고급 내용이므로, 지금 이 유닛을 진행하거나 이 과정을 통해 지식이 향상된 후에 다시 방문하셔도 됩니다.
>  
> 하지만 걱정하지 마세요. 이 보너스 유닛은 필요한 모든 정보를 포함하도록 설계되어 있어서, 파인튜닝의 내부 작동 방식을 아직 배우지 않았더라도 함수 호출을 위한 모델 파인튜닝의 모든 핵심 개념을 단계별로 안내해드릴 것입니다.

이 보너스 유닛을 따라가기 위한 최선의 방법은 다음과 같습니다:

1. Transformers로 LLM을 파인튜닝하는 방법을 알고 있어야 합니다. 아직 모르신다면 [여기](https://huggingface.co/learn/nlp-course/chapter3/1?fw=pt)를 확인해주세요.

2. `SFTTrainer`를 사용하여 모델을 파인튜닝하는 방법을 알아야 합니다. 더 자세히 알아보려면 [이 문서](https://huggingface.co/learn/nlp-course/en/chapter11/1)를 확인해주세요.

---

## 학습 내용

1. **함수 호출**  
   현대 LLM이 대화를 효과적으로 구성하여 **도구**를 트리거할 수 있게 하는 방법.

2. **LoRA (Low-Rank Adaptation)**  
   계산 및 저장 오버헤드를 줄이는 **가볍고 효율적인** 파인튜닝 방법. LoRA는 대형 모델의 학습을 *더 빠르고, 더 저렴하고, 배포하기 더 쉽게* 만듭니다.

3. **함수 호출 모델의 사고 → 행동 → 관찰 주기**  
   모델이 함수를 언제(그리고 어떻게) 호출할지, 중간 단계를 추적하고, 외부 도구나 API의 결과를 해석하는 방법을 구성하는 간단하지만 강력한 접근 방식.

4. **새로운 특수 토큰**  
   모델이 다음을 구분하는 데 도움이 되는 **특수 마커**를 소개할 것입니다:
   - 내부 "사고 과정" 추론  
   - 외부 함수 호출  
   - 외부 도구로부터 돌아오는 응답

---

이 보너스 유닛이 끝나면 다음과 같은 것을 할 수 있게 됩니다:

- 도구와 관련된 API의 내부 작동 방식을 **이해**할 수 있습니다.  
- LoRA 기술을 사용하여 모델을 **파인튜닝**할 수 있습니다.  
- 견고하고 유지보수가 가능한 함수 호출 워크플로우를 만들기 위해 사고 → 행동 → 관찰 주기를 **구현**하고 **수정**할 수 있습니다.  
- 모델의 내부 추론과 외부 액션을 원활하게 분리하기 위한 특수 토큰을 **설계하고 활용**할 수 있습니다.

그리고 **함수 호출을 수행하는 자신만의 모델을 파인튜닝**하게 될 것입니다. 🔥

**함수 호출**에 대해 알아보겠습니다! 