# 소개 [[introduction]]

![Bonus Unit 1 Thumbnail](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/bonus-unit1/thumbnail.jpg)

첫 번째 **보너스 유닛**에 오신 것을 환영합니다. 이곳에서 여러분은 **함수 호출(function calling)**을 위해 대형 언어 모델(LLM)을 **파인튜닝**하는 방법을 배우게 됩니다.

LLM 분야에서 함수 호출은 빠르게 *필수* 기술이 되고 있습니다.

이 유닛에서 우리는 단순히 프롬프트 기반 접근법에 의존했던 1유닛의 방법을 넘어서, 모델이 학습 과정에서 **행동을 취하고 관찰을 해석**하도록 훈련하여 AI를 더욱 견고하게 만드는 방법을 살펴봅니다.

> **이 보너스 유닛은 언제 진행하면 좋을까요?**
>
> 이 섹션은 **선택 사항**이며 1유닛보다 더 고급 내용이므로, 지금 바로 진행해도 좋고 코스를 통해 지식이 쌓인 뒤 돌아와도 괜찮습니다.
>
> 걱정하지 마세요. 이 보너스 유닛에는 필요한 모든 정보가 포함되어 있으므로, 파인튜닝의 세부 과정을 아직 배우지 않았다 하더라도 함수 호출 모델을 파인튜닝하는 핵심 개념을 단계별로 안내해 드립니다.

이 보너스 유닛을 수월하게 따라오기 위해서는 다음을 알고 있으면 좋습니다.

1. 트랜스포머(Transformers)를 사용해 LLM을 파인튜닝하는 방법을 알고 있다면 좋습니다. 만약 잘 모르겠다면 [여기](https://huggingface.co/learn/nlp-course/chapter3/1?fw=pt)를 참고하세요.
2. `SFTTrainer`로 모델을 파인튜닝하는 방법을 알고 있으면 좋습니다. 자세한 내용은 [이 문서](https://huggingface.co/learn/nlp-course/en/chapter11/1)를 확인하세요.

---

## 배울 내용

1. **함수 호출(Function Calling)**
   현대 LLM이 대화를 구조화하여 **툴을** 효과적으로 호출하는 방법을 배웁니다.
2. **LoRA(Low-Rank Adaptation)**
   계산 및 저장 부담을 줄여주는 **가볍고 효율적인** 파인튜닝 기법으로, 대형 모델을 *더 빠르고 저렴하며 쉽게* 학습시킬 수 있습니다.
3. **생각 → 행동 → 관찰(Thought → Act → Observe) 사이클**
   언제(그리고 어떻게) 함수를 호출하고 중간 단계를 추적하며 외부 툴이나 API의 결과를 해석할지 모델의 흐름을 구성하는 간단하면서도 강력한 접근법입니다.
4. **새로운 특수 토큰들**
   모델이 다음을 구분하도록 돕는 **특수 마커**를 소개합니다:
   - 내부 "chain-of-thought" 추론
   - 외부 함수 호출
   - 외부 툴에서 돌아오는 응답

---

이 보너스 유닛을 마치면 다음을 할 수 있게 됩니다:

- 툴과 관련된 API의 내부 동작을 **이해**합니다.
- LoRA 기법을 사용해 모델을 **파인튜닝**합니다.
- Thought → Act → Observe 사이클을 **구현**하고 **수정**하여 견고하고 유지 관리가 쉬운 함수 호출 워크플로를 만듭니다.
- 모델의 내부 추론과 외부 동작을 깔끔하게 분리할 수 있도록 **특수 토큰을 설계하고 활용**합니다.

그리고 여러분은 **자신만의 함수 호출 모델을 파인튜닝**하게 될 것입니다. 🔥

지금부터 **함수 호출**의 세계로 들어가 봅시다!
