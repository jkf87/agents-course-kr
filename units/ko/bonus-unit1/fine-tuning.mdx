# 함수 호출을 위한 모델 파인튜닝 [[fine-tuning]]

이제 첫 번째 함수 호출 모델을 파인튜닝할 준비가 되었습니다 🔥.

## 함수 호출 모델을 어떻게 학습시킬까요?

> 정답: **데이터**가 필요합니다

모델 학습 과정은 세 단계로 나눌 수 있습니다:

1. **모델을 대량의 데이터로 사전 학습**합니다. 이 단계의 결과는 **사전 학습된 모델**입니다. 예를 들어 [google/gemma-2-2b](https://huggingface.co/google/gemma-2-2b)는 기본 모델로, 강력한 지침 따르기 능력 없이 **다음 토큰 예측**만 할 수 있습니다.
2. 대화형 모델로 활용하려면 이후 **파인튜닝**을 통해 지침을 따르도록 학습시켜야 합니다. 이 단계는 모델 제작자나 오픈소스 커뮤니티, 또는 여러분이 직접 수행할 수 있습니다. 예로 [google/gemma-2-2b-it](https://huggingface.co/google/gemma-2-2b-it)은 Gemma 프로젝트 팀이 지침 준수를 위해 파인튜닝한 모델입니다.
3. 마지막으로 모델을 **사용자 요구에 맞게 정렬(alignment)**할 수 있습니다. 예를 들어 고객 서비스 챗봇이라면 고객에게 무례하게 굴어서는 안 되겠죠.

일반적으로 Gemini나 Mistral과 같은 완성된 제품은 **세 단계 모두**를 거치지만, Hugging Face에서 찾을 수 있는 모델들은 이 중 한 단계 이상을 완료한 상태입니다.

이 튜토리얼에서는 [google/gemma-2-2b-it](https://huggingface.co/google/gemma-2-2b-it)을 기반으로 함수 호출 모델을 구축합니다. 기본 모델인 [google/gemma-2-2b](https://huggingface.co/google/gemma-2-2b) 대신 이미 파인튜닝된 모델을 사용하는 이유는 우리의 활용 사례에 더 적합하기 때문입니다.

사전 학습 모델부터 시작하면 **지침 따르기, 대화, 함수 호출**을 모두 학습시키기 위해 더 많은 훈련이 필요합니다.

지침 기반 모델에서 시작하면 **우리 모델이 학습해야 할 정보량을 최소화**할 수 있습니다.

## LoRA(Low-Rank Adaptation)

LoRA는 학습해야 할 매개변수 수를 크게 **줄여 주는** 널리 사용되는 가볍고 효율적인 학습 기법입니다.

모델에 **어댑터 형태의 적은 수의 가중치**를 삽입하여 학습하는 방식으로 동작합니다. 이를 통해 학습 속도가 빨라지고 메모리 사용이 적으며, 수백 MB 정도의 작은 모델 가중치를 생성해 보관과 공유가 수월합니다.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/blog_multi-lora-serving_LoRA.gif" alt="LoRA inference" width="50%"/>

LoRA는 주로 선형 계층 등 트랜스포머 층에 랭크 분해 행렬 쌍을 추가합니다. 학습 중에는 나머지 모델을 "동결"하고 새로 추가된 어댑터의 가중치만 업데이트합니다.

이렇게 하면 학습해야 할 **파라미터 수**가 크게 줄어 어댑터 가중치만 업데이트하면 됩니다.

추론 시에는 입력이 어댑터와 기본 모델에 모두 전달되거나, 어댑터 가중치를 기본 모델과 병합하여 추가 지연 없이 사용할 수 있습니다.

LoRA는 **대형** 언어 모델을 특정 작업이나 도메인에 맞게 조정하면서 자원 요구 사항을 관리하기 좋습니다. 이는 모델 학습에 **필요한 메모리**를 줄이는 데 도움이 됩니다.

LoRA의 작동 방식이 궁금하다면 [이 튜토리얼](https://huggingface.co/learn/nlp-course/chapter11/4?fw=pt)을 확인해 보세요.

## 함수 호출 모델 파인튜닝 실습

튜토리얼 노트북은 👉 [여기](https://huggingface.co/agents-course/notebooks/blob/main/bonus-unit1/bonus-unit1.ipynb)에서 확인할 수 있습니다.

그리고 [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/#fileId=https://huggingface.co/agents-course/notebooks/blob/main/bonus-unit1/bonus-unit1.ipynb)을 클릭하여 Colab 노트북에서 실행해 볼 수 있습니다.
