# 사고: 내부 추론과 ReAct 접근법

<Tip>
이 섹션에서는 AI 에이전트의 내부 작동 방식—추론하고 계획하는 능력—을 자세히 살펴봅니다. 에이전트가 정보를 분석하고, 복잡한 문제를 관리 가능한 단계로 나누고, 다음에 취할 액션을 결정하기 위해 내부 대화를 어떻게 활용하는지 알아볼 것입니다. 또한 모델이 행동하기 전에 "단계별로" 생각하도록 장려하는 프롬프팅 기법인 ReAct 접근법을 소개합니다.
</Tip>

사고는 **에이전트가 작업을 해결하기 위한 내부 추론과 계획 과정**을 나타냅니다.

이는 에이전트의 대규모 언어 모델(LLM) 능력을 활용하여 **프롬프트에 제시된 정보를 분석**합니다.

이것은 에이전트가 주어진 작업을 고려하고 접근 방식을 전략화하는 내부 대화라고 생각하면 됩니다.

에이전트의 사고는 현재 관찰을 접근하고 다음 액션이 무엇이 되어야 하는지 결정하는 역할을 합니다.

이 과정을 통해 에이전트는 **복잡한 문제를 더 작고 관리하기 쉬운 단계로 나누고**, 과거 경험을 반영하며, 새로운 정보를 바탕으로 계획을 지속적으로 조정할 수 있습니다.

다음은 일반적인 사고의 예시입니다:

| 사고 유형 | 예시 |
|-----------|------|
| 계획 | "이 작업을 세 단계로 나누어야 합니다: 1) 데이터 수집, 2) 트렌드 분석, 3) 보고서 생성" |
| 분석 | "오류 메시지를 보니 데이터베이스 연결 매개변수에 문제가 있는 것 같습니다" |
| 의사결정 | "사용자의 예산 제약을 고려할 때, 중간 등급 옵션을 추천해야 할 것 같습니다" |
| 문제 해결 | "이 코드를 최적화하려면 먼저 프로파일링하여 병목 지점을 찾아야 합니다" |
| 기억 통합 | "사용자가 이전에 Python을 선호한다고 언급했으니, Python으로 예시를 제공하겠습니다" |
| 자기 성찰 | "이전 접근 방식이 잘 작동하지 않았으니, 다른 전략을 시도해야 합니다" |
| 목표 설정 | "이 작업을 완료하려면 먼저 수용 기준을 설정해야 합니다" |
| 우선순위 지정 | "새로운 기능을 추가하기 전에 보안 취약점을 해결해야 합니다" |

> **참고:** 함수 호출을 위해 미세 조정된 LLM의 경우, 사고 과정은 선택적입니다.
> *함수 호출에 익숙하지 않으시다면, 액션 섹션에서 더 자세한 내용을 다룰 것입니다.*

## ReAct 접근법

핵심 방법 중 하나는 "추론"(Think)과 "행동"(Act)을 결합한 **ReAct 접근법**입니다.

ReAct는 LLM이 다음 토큰을 디코딩하기 전에 "단계별로 생각해봅시다"라는 문구를 추가하는 간단한 프롬프팅 기법입니다.

실제로, 모델에게 "단계별로" 생각하도록 프롬프팅하면 모델이 문제를 *하위 작업*으로 **분해**하도록 장려되므로, 최종 해결책보다는 **계획을 생성**하는 방향으로 디코딩 과정이 진행됩니다.

이를 통해 모델은 하위 단계를 더 자세히 고려할 수 있으며, 일반적으로 최종 해결책을 직접 생성하려고 시도하는 것보다 오류가 적게 발생합니다.

<figure>
<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/ReAct.png" alt="ReAct"/>
<figcaption>(d)는 "단계별로 생각해봅시다"라는 프롬프트를 사용하는 ReAct 접근법의 예시입니다
</figcaption>
</figure>

<Tip>
최근 추론 전략에 대한 관심이 많아졌습니다. 이는 Deepseek R1이나 OpenAI의 o1과 같이 "답변하기 전에 생각하도록" 미세 조정된 모델들의 기반이 되는 개념입니다.

이러한 모델들은 특정 _사고_ 섹션(특수 토큰 `<think>`와 `</think>` 사이에 포함)을 항상 포함하도록 훈련되었습니다. 이는 ReAct와 같은 단순한 프롬프팅 기법이 아니라, 우리가 기대하는 바를 보여주는 수천 개의 예시를 분석한 후 이러한 섹션을 생성하는 방법을 모델이 학습하는 훈련 방법입니다.
</Tip>

---
이제 사고 과정을 더 잘 이해했으니, 과정의 두 번째 부분인 액션에 대해 더 자세히 알아보겠습니다.